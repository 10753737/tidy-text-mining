<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Tidy Text Mining with R</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools">
  <meta name="generator" content="bookdown 0.1 and GitBook 2.6.7">

  <meta property="og:title" content="Tidy Text Mining with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  <meta name="github-repo" content="dgrtwo/tidy-text-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tidy Text Mining with R" />
  
  <meta name="twitter:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  

<meta name="author" content="Julia Silge and David Robinson">

<meta name="date" content="2016-10-28">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ngrams.html">
<link rel="next" href="topicmodeling.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Tidy Text Mining with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to Tidy Text Mining with R</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-tidy-text"><i class="fa fa-check"></i><b>1.1</b> What is tidy text?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#about-this-book"><i class="fa fa-check"></i><b>1.2</b> About this book</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#outline"><i class="fa fa-check"></i><b>1.3</b> Outline</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#topics-this-book-does-not-cover"><i class="fa fa-check"></i><b>1.4</b> Topics this book does not cover</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#acknowledgements"><i class="fa fa-check"></i><b>1.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidytext.html"><a href="tidytext.html"><i class="fa fa-check"></i><b>2</b> The tidy text format</a><ul>
<li class="chapter" data-level="2.1" data-path="tidytext.html"><a href="tidytext.html#the-unnest_tokens-function"><i class="fa fa-check"></i><b>2.1</b> The <code>unnest_tokens</code> function</a></li>
<li class="chapter" data-level="2.2" data-path="tidytext.html"><a href="tidytext.html#tidying-the-works-of-jane-austen"><i class="fa fa-check"></i><b>2.2</b> Tidying the works of Jane Austen</a></li>
<li class="chapter" data-level="2.3" data-path="tidytext.html"><a href="tidytext.html#the-gutenbergr-package"><i class="fa fa-check"></i><b>2.3</b> The gutenbergr package</a></li>
<li class="chapter" data-level="2.4" data-path="tidytext.html"><a href="tidytext.html#word-frequencies"><i class="fa fa-check"></i><b>2.4</b> Word frequencies</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentiment.html"><a href="sentiment.html"><i class="fa fa-check"></i><b>3</b> Sentiment analysis with tidy data</a><ul>
<li class="chapter" data-level="3.1" data-path="sentiment.html"><a href="sentiment.html#the-sentiments-dataset"><i class="fa fa-check"></i><b>3.1</b> The <code>sentiments</code> dataset</a></li>
<li class="chapter" data-level="3.2" data-path="sentiment.html"><a href="sentiment.html#sentiment-analysis-with-inner-join"><i class="fa fa-check"></i><b>3.2</b> Sentiment analysis with inner join</a></li>
<li class="chapter" data-level="3.3" data-path="sentiment.html"><a href="sentiment.html#most-common-positive-and-negative-words"><i class="fa fa-check"></i><b>3.3</b> Most common positive and negative words</a></li>
<li class="chapter" data-level="3.4" data-path="sentiment.html"><a href="sentiment.html#wordclouds"><i class="fa fa-check"></i><b>3.4</b> Wordclouds</a></li>
<li class="chapter" data-level="3.5" data-path="sentiment.html"><a href="sentiment.html#looking-at-units-beyond-just-words"><i class="fa fa-check"></i><b>3.5</b> Looking at units beyond just words</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tfidf.html"><a href="tfidf.html"><i class="fa fa-check"></i><b>4</b> Analyzing word and document frequency: tf-idf</a><ul>
<li class="chapter" data-level="4.1" data-path="tfidf.html"><a href="tfidf.html#term-frequency-and-inverse-document-frequency"><i class="fa fa-check"></i><b>4.1</b> Term frequency and inverse document frequency</a></li>
<li class="chapter" data-level="4.2" data-path="tfidf.html"><a href="tfidf.html#term-frequency-in-jane-austens-novels"><i class="fa fa-check"></i><b>4.2</b> Term frequency in Jane Austen’s novels</a></li>
<li class="chapter" data-level="4.3" data-path="tfidf.html"><a href="tfidf.html#the-bind_tf_idf-function"><i class="fa fa-check"></i><b>4.3</b> The <code>bind_tf_idf</code> function</a></li>
<li class="chapter" data-level="4.4" data-path="tfidf.html"><a href="tfidf.html#a-corpus-of-physics-texts"><i class="fa fa-check"></i><b>4.4</b> A corpus of physics texts</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ngrams.html"><a href="ngrams.html"><i class="fa fa-check"></i><b>5</b> Working with combinations of words using n-grams and widyr</a><ul>
<li class="chapter" data-level="5.1" data-path="ngrams.html"><a href="ngrams.html#tokenizing-by-n-gram"><i class="fa fa-check"></i><b>5.1</b> Tokenizing by n-gram</a><ul>
<li class="chapter" data-level="5.1.1" data-path="ngrams.html"><a href="ngrams.html#counting-and-filtering-n-grams"><i class="fa fa-check"></i><b>5.1.1</b> Counting and filtering n-grams</a></li>
<li class="chapter" data-level="5.1.2" data-path="ngrams.html"><a href="ngrams.html#analyzing-bigrams"><i class="fa fa-check"></i><b>5.1.2</b> Analyzing bigrams</a></li>
<li class="chapter" data-level="5.1.3" data-path="ngrams.html"><a href="ngrams.html#using-bigrams-to-provide-context-in-sentiment-analysis"><i class="fa fa-check"></i><b>5.1.3</b> Using bigrams to provide context in sentiment analysis</a></li>
<li class="chapter" data-level="5.1.4" data-path="ngrams.html"><a href="ngrams.html#visualizing-a-network-of-bigrams-with-igraph"><i class="fa fa-check"></i><b>5.1.4</b> Visualizing a network of bigrams with igraph</a></li>
<li class="chapter" data-level="5.1.5" data-path="ngrams.html"><a href="ngrams.html#visualizing-bigrams-in-other-texts"><i class="fa fa-check"></i><b>5.1.5</b> Visualizing bigrams in other texts</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ngrams.html"><a href="ngrams.html#counting-and-correlating-pairs-of-words-with-the-widyr-package"><i class="fa fa-check"></i><b>5.2</b> Counting and correlating pairs of words with the widyr package</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ngrams.html"><a href="ngrams.html#counting-and-correlating-among-sections"><i class="fa fa-check"></i><b>5.2.1</b> Counting and correlating among sections</a></li>
<li class="chapter" data-level="5.2.2" data-path="ngrams.html"><a href="ngrams.html#pairwise-correlation"><i class="fa fa-check"></i><b>5.2.2</b> Pairwise correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="dtm.html"><a href="dtm.html"><i class="fa fa-check"></i><b>6</b> Tidying and casting document-term matrices</a><ul>
<li class="chapter" data-level="6.1" data-path="dtm.html"><a href="dtm.html#tidying-a-document-term-matrix"><i class="fa fa-check"></i><b>6.1</b> Tidying a document-term matrix</a></li>
<li class="chapter" data-level="6.2" data-path="dtm.html"><a href="dtm.html#casting-tidy-text-data-into-a-documenttermmatrix"><i class="fa fa-check"></i><b>6.2</b> Casting tidy text data into a DocumentTermMatrix</a></li>
<li class="chapter" data-level="6.3" data-path="dtm.html"><a href="dtm.html#tidying-corpus-objects-with-metadata"><i class="fa fa-check"></i><b>6.3</b> Tidying corpus objects with metadata</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="topicmodeling.html"><a href="topicmodeling.html"><i class="fa fa-check"></i><b>7</b> Topic modeling</a><ul>
<li class="chapter" data-level="7.1" data-path="topicmodeling.html"><a href="topicmodeling.html#the-great-library-heist"><i class="fa fa-check"></i><b>7.1</b> The great library heist</a></li>
<li class="chapter" data-level="7.2" data-path="topicmodeling.html"><a href="topicmodeling.html#latent-dirichlet-allocation-with-the-topicmodels-package"><i class="fa fa-check"></i><b>7.2</b> Latent Dirichlet allocation with the topicmodels package</a></li>
<li class="chapter" data-level="7.3" data-path="topicmodeling.html"><a href="topicmodeling.html#per-document-classification"><i class="fa fa-check"></i><b>7.3</b> Per-document classification</a></li>
<li class="chapter" data-level="7.4" data-path="topicmodeling.html"><a href="topicmodeling.html#by-word-assignments-augment"><i class="fa fa-check"></i><b>7.4</b> By word assignments: <code>augment</code></a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="twitter.html"><a href="twitter.html"><i class="fa fa-check"></i><b>8</b> Case study: comparing Twitter archives</a><ul>
<li class="chapter" data-level="8.1" data-path="twitter.html"><a href="twitter.html#getting-the-data-and-distribution-of-tweets"><i class="fa fa-check"></i><b>8.1</b> Getting the data and distribution of tweets</a></li>
<li class="chapter" data-level="8.2" data-path="twitter.html"><a href="twitter.html#word-frequencies-1"><i class="fa fa-check"></i><b>8.2</b> Word frequencies</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nasa.html"><a href="nasa.html"><i class="fa fa-check"></i><b>9</b> Case study: mining NASA metadata</a><ul>
<li class="chapter" data-level="9.1" data-path="nasa.html"><a href="nasa.html#getting-the-metadata"><i class="fa fa-check"></i><b>9.1</b> Getting the metadata</a></li>
<li class="chapter" data-level="9.2" data-path="nasa.html"><a href="nasa.html#wrangling-and-tidying-the-data"><i class="fa fa-check"></i><b>9.2</b> Wrangling and tidying the data</a></li>
<li class="chapter" data-level="9.3" data-path="nasa.html"><a href="nasa.html#some-initial-simple-exploration"><i class="fa fa-check"></i><b>9.3</b> Some initial simple exploration</a></li>
<li class="chapter" data-level="9.4" data-path="nasa.html"><a href="nasa.html#word-co-ocurrences"><i class="fa fa-check"></i><b>9.4</b> Word co-ocurrences</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="usenet.html"><a href="usenet.html"><i class="fa fa-check"></i><b>10</b> Case study: analyzing usenet text</a><ul>
<li class="chapter" data-level="10.1" data-path="usenet.html"><a href="usenet.html#wrangling-the-data"><i class="fa fa-check"></i><b>10.1</b> Wrangling the data</a></li>
<li class="chapter" data-level="10.2" data-path="usenet.html"><a href="usenet.html#term-frequency-and-inverse-document-frequency-tf-idf"><i class="fa fa-check"></i><b>10.2</b> Term frequency and inverse document frequency: tf-idf</a></li>
<li class="chapter" data-level="10.3" data-path="usenet.html"><a href="usenet.html#sentiment-analysis"><i class="fa fa-check"></i><b>10.3</b> Sentiment analysis</a></li>
<li class="chapter" data-level="10.4" data-path="usenet.html"><a href="usenet.html#sentiment-analysis-by-word"><i class="fa fa-check"></i><b>10.4</b> Sentiment analysis by word</a></li>
<li class="chapter" data-level="10.5" data-path="usenet.html"><a href="usenet.html#sentiment-analysis-by-message"><i class="fa fa-check"></i><b>10.5</b> Sentiment analysis by message</a></li>
<li class="chapter" data-level="10.6" data-path="usenet.html"><a href="usenet.html#n-grams"><i class="fa fa-check"></i><b>10.6</b> N-grams</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>11</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tidy Text Mining with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="dtm" class="section level1">
<h1><span class="header-section-number">6</span> Tidying and casting document-term matrices</h1>
<p>So far, we’ve been analyzing data in a tidy text structure: a data frame with one-token-per-document-per-row. This lets us use the popular suite of tidy tools such as dplyr, tidyr, and ggplot2. We’ve demonstrated that many text analyses can be performed using these principles.</p>
<p>But many of the existing tools for natural language processing don’t work with this kind of structure. The <a href="https://cran.r-project.org/web/views/NaturalLanguageProcessing.html">CRAN Task View for Natural Language Processing</a> lists a large selection of packages that take other inputs. One of the most common is the <a href="https://en.wikipedia.org/wiki/Document-term_matrix">document-term matrix</a>, a sparse matrix with one row for each document in a collection and one column for each term or word. The value that goes into the matrix is usually a word count or sometimes tf-idf. These matrices are sparse (they consist mostly of zeroes), so special algorithms and data structures can be used to deal with them that are efficient and fast.</p>
<p>The tidytext package can integrate these packages into an analysis while still relying on our tidy tools. The two key verbs are:</p>
<ul>
<li><code>tidy()</code>: Constructs a data frame that summarizes a model’s statistical findings.</li>
<li><code>cast_</code>: Turns a tidy one-term-per-row data frame into a document-term matrix. This includes <code>cast_sparse()</code> (sparse Matrix), <code>cast_dtm()</code> (<code>DocumentTermMatrix</code> objects from tm), and <code>cast_dfm()</code> (<code>dfm</code> objects from quanteda).</li>
</ul>
<div id="tidying-a-document-term-matrix" class="section level2">
<h2><span class="header-section-number">6.1</span> Tidying a document-term matrix</h2>
<p>As we have discussed, many existing text mining datasets expect and provide a <strong>document-term matrix</strong>, or DTM. A DTM is a matrix where</p>
<ul>
<li>each row represents one document,</li>
<li>each column represents one term, and</li>
<li>each value typically contains the number of appearances of that term in that document.</li>
</ul>
<p>DTMs are usually implemented as sparse matrices, meaning the vast majority of values are 0. These objects can be interacted with as though they were matrices, but are stored in a more efficient format.</p>
<p>One commonly used implementation of DTMs in R is the <code>DocumentTermMatrix</code> class in the tm package. For example, consider the corpus of 2246 Associated Press articles from the topicmodels package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tm)

<span class="kw">data</span>(<span class="st">&quot;AssociatedPress&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;topicmodels&quot;</span>)
<span class="kw">class</span>(AssociatedPress)</code></pre></div>
<pre><code>## [1] &quot;DocumentTermMatrix&quot;    &quot;simple_triplet_matrix&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AssociatedPress</code></pre></div>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 2246, terms: 10473)&gt;&gt;
## Non-/sparse entries: 302031/23220327
## Sparsity           : 99%
## Maximal term length: 18
## Weighting          : term frequency (tf)</code></pre>
<p>We see that this dataset contains documents (each of them an AP article) and terms (words). Notice that this example DTM is 99% sparse.</p>
<p>If we want to analyze this with tidy tools, we need to turn it into a one-token-per-document-per-row data frame first. The broom package <span class="citation">(Robinson et al. <a href="#ref-R-broom">2015</a>)</span> introduced the <code>tidy</code> verb, which takes a non-tidy object and turns it into a data frame. The tidytext package implements that method for <code>DocumentTermClass</code> objects:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(tidytext)

ap_td &lt;-<span class="st"> </span><span class="kw">tidy</span>(AssociatedPress)
ap_td</code></pre></div>
<pre><code>## # A tibble: 302,031 × 3
##    document       term count
##       &lt;int&gt;      &lt;chr&gt; &lt;dbl&gt;
## 1         1     adding     1
## 2         1      adult     2
## 3         1        ago     1
## 4         1    alcohol     1
## 5         1  allegedly     1
## 6         1      allen     1
## 7         1 apparently     2
## 8         1   appeared     1
## 9         1   arrested     1
## 10        1    assault     1
## # ... with 302,021 more rows</code></pre>
<p>Notice that we now have a tidy three-column <code>tbl_df</code>, with variables <code>document</code>, <code>term</code>, and <code>count</code>. This tidying operation is similar to the <code>melt</code> function from the reshape2 package <span class="citation">(Wickham <a href="#ref-R-reshape2">2007</a>)</span> for non-sparse matrices.</p>
<p>As we’ve seen in chapters 2-5, this form is convenient for analysis with the dplyr and tidytext packages. For example, you can perform sentiment analysis on these newspaper articles.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ap_sentiments &lt;-<span class="st"> </span>ap_td %&gt;%
<span class="st">  </span><span class="kw">inner_join</span>(<span class="kw">get_sentiments</span>(<span class="st">&quot;bing&quot;</span>), <span class="dt">by =</span> <span class="kw">c</span>(<span class="dt">term =</span> <span class="st">&quot;word&quot;</span>))

ap_sentiments</code></pre></div>
<pre><code>## # A tibble: 30,094 × 4
##    document    term count sentiment
##       &lt;int&gt;   &lt;chr&gt; &lt;dbl&gt;     &lt;chr&gt;
## 1         1 assault     1  negative
## 2         1 complex     1  negative
## 3         1   death     1  negative
## 4         1    died     1  negative
## 5         1    good     2  positive
## 6         1 illness     1  negative
## 7         1  killed     2  negative
## 8         1    like     2  positive
## 9         1   liked     1  positive
## 10        1 miracle     1  positive
## # ... with 30,084 more rows</code></pre>
<p>This could, for example, let us visualize which words from these AP articles most often contributed to positive or negative sentiment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)

ap_sentiments %&gt;%
<span class="st">  </span><span class="kw">count</span>(sentiment, term, <span class="dt">wt =</span> count) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">filter</span>(n &gt;=<span class="st"> </span><span class="dv">150</span>) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n =</span> <span class="kw">ifelse</span>(sentiment ==<span class="st"> &quot;negative&quot;</span>, -n, n)) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">reorder</span>(term, n)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(term, n, <span class="dt">fill =</span> sentiment)) +
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Contribution to sentiment&quot;</span>) +
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><img src="06-document-term-matrices_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>A tidier is also available for the <code>dfm</code> (document-feature matrix) class from the quanteda package <span class="citation">(Benoit and Nulty <a href="#ref-R-quanteda">2016</a>)</span>. Consider the corpus of presidential inauguration speeches that comes with the quanteda package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(methods)

<span class="kw">data</span>(<span class="st">&quot;inaugCorpus&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;quanteda&quot;</span>)
d &lt;-<span class="st"> </span>quanteda::<span class="kw">dfm</span>(inaugCorpus)

d</code></pre></div>
<pre><code>## Document-feature matrix of: 57 documents, 9,215 features.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(d)</code></pre></div>
<pre><code>## # A tibble: 43,719 × 3
##           document            term count
##              &lt;chr&gt;           &lt;chr&gt; &lt;dbl&gt;
## 1  1789-Washington fellow-citizens     1
## 2       1797-Adams fellow-citizens     3
## 3   1801-Jefferson fellow-citizens     2
## 4     1809-Madison fellow-citizens     1
## 5     1813-Madison fellow-citizens     1
## 6      1817-Monroe fellow-citizens     5
## 7      1821-Monroe fellow-citizens     1
## 8    1841-Harrison fellow-citizens    11
## 9        1845-Polk fellow-citizens     1
## 10     1849-Taylor fellow-citizens     1
## # ... with 43,709 more rows</code></pre>
<p>We could find the words most specific to several inaugural speeches using <code>bind_tf_idf</code> from chapter 4:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">speeches &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;1861-Lincoln&quot;</span>, <span class="st">&quot;1945-Roosevelt&quot;</span>,
              <span class="st">&quot;1961-Kennedy&quot;</span>, <span class="st">&quot;2009-Obama&quot;</span>)

inaug_tf_idf &lt;-<span class="st"> </span><span class="kw">tidy</span>(d) %&gt;%
<span class="st">  </span><span class="kw">bind_tf_idf</span>(term, document, count) %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(tf_idf)) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(document %in%<span class="st"> </span>speeches)

inaug_tf_idf</code></pre></div>
<pre><code>## # A tibble: 2,690 × 6
##          document         term count          tf      idf      tf_idf
##             &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
## 1  1945-Roosevelt      learned     5 0.009009009 1.845827 0.016629069
## 2  1945-Roosevelt        trend     2 0.003603604 3.349904 0.012071726
## 3  1945-Roosevelt         test     3 0.005405405 2.097141 0.011335898
## 4    1961-Kennedy        sides     8 0.005865103 1.845827 0.010825963
## 5  1945-Roosevelt     mistakes     2 0.003603604 2.944439 0.010610591
## 6  1945-Roosevelt       upward     2 0.003603604 2.656757 0.009573899
## 7  1945-Roosevelt         gain     2 0.003603604 2.433613 0.008769778
## 8  1945-Roosevelt   well-being     2 0.003603604 2.251292 0.008112763
## 9  1945-Roosevelt    faintness     1 0.001801802 4.043051 0.007284777
## 10 1945-Roosevelt schoolmaster     1 0.001801802 4.043051 0.007284777
## # ... with 2,680 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inaug_tf_idf %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(document) %&gt;%
<span class="st">  </span><span class="kw">top_n</span>(<span class="dv">8</span>, tf_idf) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">term =</span> <span class="kw">reorder</span>(term, tf_idf)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(term, tf_idf, <span class="dt">fill =</span> document)) +
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>,<span class="dt">show.legend =</span> <span class="ot">FALSE</span>) +
<span class="st">  </span><span class="kw">facet_wrap</span>(~<span class="st"> </span>document, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) +
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><img src="06-document-term-matrices_files/figure-html/presidents-1.png" width="768" /></p>
</div>
<div id="casting-tidy-text-data-into-a-documenttermmatrix" class="section level2">
<h2><span class="header-section-number">6.2</span> Casting tidy text data into a DocumentTermMatrix</h2>
<p>Some existing text mining tools or algorithms work only on sparse document-term matrices. Therefore, tidytext provides <code>cast_</code> verbs for converting from a tidy form to these matrices.</p>
<p>For example, we could take the tidied AP dataset and cast it back into a document-term matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ap_td</code></pre></div>
<pre><code>## # A tibble: 302,031 × 3
##    document       term count
##       &lt;int&gt;      &lt;chr&gt; &lt;dbl&gt;
## 1         1     adding     1
## 2         1      adult     2
## 3         1        ago     1
## 4         1    alcohol     1
## 5         1  allegedly     1
## 6         1      allen     1
## 7         1 apparently     2
## 8         1   appeared     1
## 9         1   arrested     1
## 10        1    assault     1
## # ... with 302,021 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ap_td %&gt;%
<span class="st">  </span><span class="kw">cast_dtm</span>(document, term, count)</code></pre></div>
<pre><code>## &lt;&lt;DocumentTermMatrix (documents: 2246, terms: 10473)&gt;&gt;
## Non-/sparse entries: 302031/23220327
## Sparsity           : 99%
## Maximal term length: 18
## Weighting          : term frequency (tf)</code></pre>
<p>Similarly, we could cast it into a Term-Document Matrix with <code>cast_tdm</code>, or quanteda’s dfm with <code>cast_dfm</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># cast into a Term-Document Matrix</span>
ap_td %&gt;%
<span class="st">  </span><span class="kw">cast_tdm</span>(term, document, count)</code></pre></div>
<pre><code>## &lt;&lt;TermDocumentMatrix (terms: 10473, documents: 2246)&gt;&gt;
## Non-/sparse entries: 302031/23220327
## Sparsity           : 99%
## Maximal term length: 18
## Weighting          : term frequency (tf)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># cast into quanteda&#39;s dfm</span>
ap_td %&gt;%
<span class="st">  </span><span class="kw">cast_dfm</span>(term, document, count)</code></pre></div>
<pre><code>## Document-feature matrix of: 10,473 documents, 2,246 features.</code></pre>
<p>Some tools simply require a sparse matrix:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Matrix)

<span class="co"># cast into a Matrix object</span>
m &lt;-<span class="st"> </span>ap_td %&gt;%
<span class="st">  </span><span class="kw">cast_sparse</span>(document, term, count)

<span class="kw">class</span>(m)</code></pre></div>
<pre><code>## [1] &quot;dgCMatrix&quot;
## attr(,&quot;package&quot;)
## [1] &quot;Matrix&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(m)</code></pre></div>
<pre><code>## [1]  2246 10473</code></pre>
<p>This casting process allows for easy reading, filtering, and processing to be done using dplyr and other tidy tools, after which the data can be converted into a document-term matrix for machine learning applications.</p>
</div>
<div id="tidying-corpus-objects-with-metadata" class="section level2">
<h2><span class="header-section-number">6.3</span> Tidying corpus objects with metadata</h2>
<p>You can also tidy Corpus objects from the tm package. For example, consider a Corpus containing 20 documents:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reut21578 &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;texts&quot;</span>, <span class="st">&quot;crude&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;tm&quot;</span>)
reuters &lt;-<span class="st"> </span><span class="kw">VCorpus</span>(<span class="kw">DirSource</span>(reut21578),
                   <span class="dt">readerControl =</span> <span class="kw">list</span>(<span class="dt">reader =</span> readReut21578XMLasPlain))

reuters</code></pre></div>
<pre><code>## &lt;&lt;VCorpus&gt;&gt;
## Metadata:  corpus specific: 0, document level (indexed): 0
## Content:  documents: 20</code></pre>
<p>The <code>tidy</code> verb creates a table with one row per document:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reuters_td &lt;-<span class="st"> </span><span class="kw">tidy</span>(reuters)
reuters_td</code></pre></div>
<pre><code>## # A tibble: 20 × 17
##                        author       datetimestamp description
##                         &lt;chr&gt;              &lt;dttm&gt;       &lt;chr&gt;
## 1                        &lt;NA&gt; 1987-02-26 17:00:56            
## 2  BY TED D&#39;AFFLISIO, Reuters 1987-02-26 17:34:11            
## 3                        &lt;NA&gt; 1987-02-26 18:18:00            
## 4                        &lt;NA&gt; 1987-02-26 18:21:01            
## 5                        &lt;NA&gt; 1987-02-26 19:00:57            
## 6                        &lt;NA&gt; 1987-03-01 03:25:46            
## 7    By Jeremy Clift, Reuters 1987-03-01 03:39:14            
## 8                        &lt;NA&gt; 1987-03-01 05:27:27            
## 9                        &lt;NA&gt; 1987-03-01 08:22:30            
## 10                       &lt;NA&gt; 1987-03-01 18:31:44            
## 11                       &lt;NA&gt; 1987-03-02 01:05:49            
## 12                       &lt;NA&gt; 1987-03-02 07:39:23            
## 13                       &lt;NA&gt; 1987-03-02 07:43:22            
## 14                       &lt;NA&gt; 1987-03-02 07:43:41            
## 15                       &lt;NA&gt; 1987-03-02 08:25:42            
## 16                       &lt;NA&gt; 1987-03-02 11:20:05            
## 17                       &lt;NA&gt; 1987-03-02 11:28:26            
## 18                       &lt;NA&gt; 1987-03-02 12:13:46            
## 19 By BERNICE NAPACH, Reuters 1987-03-02 14:38:34            
## 20                       &lt;NA&gt; 1987-03-02 14:49:06            
##                                              heading    id language            origin
##                                                &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;             &lt;chr&gt;
## 1           DIAMOND SHAMROCK (DIA) CUTS CRUDE PRICES   127       en Reuters-21578 XML
## 2    OPEC MAY HAVE TO MEET TO FIRM PRICES - ANALYSTS   144       en Reuters-21578 XML
## 3          TEXACO CANADA &lt;TXC&gt; LOWERS CRUDE POSTINGS   191       en Reuters-21578 XML
## 4          MARATHON PETROLEUM REDUCES CRUDE POSTINGS   194       en Reuters-21578 XML
## 5          HOUSTON OIL &lt;HO&gt; RESERVES STUDY COMPLETED   211       en Reuters-21578 XML
## 6      KUWAIT SAYS NO PLANS FOR EMERGENCY OPEC TALKS   236       en Reuters-21578 XML
## 7  INDONESIA SEEN AT CROSSROADS OVER ECONOMIC CHANGE   237       en Reuters-21578 XML
## 8              SAUDI RIYAL DEPOSIT RATES REMAIN FIRM   242       en Reuters-21578 XML
## 9            QATAR UNVEILS BUDGET FOR FISCAL 1987/88   246       en Reuters-21578 XML
## 10   SAUDI ARABIA REITERATES COMMITMENT TO OPEC PACT   248       en Reuters-21578 XML
## 11    SAUDI FEBRUARY CRUDE OUTPUT PUT AT 3.5 MLN BPD   273       en Reuters-21578 XML
## 12 GULF ARAB DEPUTY OIL MINISTERS TO MEET IN BAHRAIN   349       en Reuters-21578 XML
## 13 SAUDI ARABIA REITERATES COMMITMENT TO OPEC ACCORD   352       en Reuters-21578 XML
## 14  KUWAIT MINISTER SAYS NO EMERGENCY OPEC TALKS SET   353       en Reuters-21578 XML
## 15          PHILADELPHIA PORT CLOSED BY TANKER CRASH   368       en Reuters-21578 XML
## 16     STUDY GROUP URGES INCREASED U.S. OIL RESERVES   489       en Reuters-21578 XML
## 17     STUDY GROUP URGES INCREASED U.S. OIL RESERVES   502       en Reuters-21578 XML
## 18    UNOCAL &lt;UCL&gt; UNIT CUTS CRUDE OIL POSTED PRICES   543       en Reuters-21578 XML
## 19      NYMEX WILL EXPAND OFF-HOUR TRADING APRIL ONE   704       en Reuters-21578 XML
## 20     ARGENTINE OIL PRODUCTION DOWN IN JANUARY 1987   708       en Reuters-21578 XML
## # ... with 10 more variables: topics &lt;chr&gt;, lewissplit &lt;chr&gt;, cgisplit &lt;chr&gt;, oldid &lt;chr&gt;,
## #   topics_cat &lt;list&gt;, places &lt;list&gt;, people &lt;chr&gt;, orgs &lt;chr&gt;, exchanges &lt;chr&gt;, text &lt;chr&gt;</code></pre>
<p>Another variation of a corpus object is <code>corpus</code> from the quanteda package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(quanteda)

<span class="kw">data</span>(<span class="st">&quot;inaugCorpus&quot;</span>)

inaugCorpus</code></pre></div>
<pre><code>## Corpus consisting of 57 documents and 3 docvars.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inaug_td &lt;-<span class="st"> </span><span class="kw">tidy</span>(inaugCorpus)
inaug_td</code></pre></div>
<pre><code>## # A tibble: 57 × 4
##                                                                                                                                                        text
## *                                                                                                                                                     &lt;chr&gt;
## 1  Fellow-Citizens of the Senate and of the House of Representatives:\n\nAmong the vicissitudes incident to life no event could have filled me with greater
## 2    Fellow citizens, I am again called upon by the voice of my country to execute the functions of its Chief Magistrate. When the occasion proper for it s
## 3    When it was first perceived, in early times, that no middle course for America remained between unlimited submission to a foreign legislature and a to
## 4  Friends and Fellow Citizens:\n\nCalled upon to undertake the duties of the first executive office of our country, I avail myself of the presence of that
## 5    Proceeding, fellow citizens, to that qualification which the Constitution requires before my entrance on the charge again conferred on me, it is my du
## 6    Unwilling to depart from examples of the most revered authority, I avail myself of the occasion now presented to express the profound impression made 
## 7    About to add the solemnity of an oath to the obligations imposed by a second call to the station in which my country heretofore placed me, I find in t
## 8    I should be destitute of feeling if I was not deeply affected by the strong proof which my fellow-citizens have given me of their confidence in callin
## 9    Fellow citizens, I shall not attempt to describe the grateful emotions which the new and very distinguished proof of the confidence of my fellow citiz
## 10   In compliance with an usage coeval with the existence of our Federal Constitution, and sanctioned by the example of my predecessors in the career upon
## # ... with 47 more rows, and 3 more variables: Year &lt;int&gt;, President &lt;chr&gt;, FirstName &lt;chr&gt;</code></pre>
<p>This lets us work with tidy tools like <code>unnest_tokens</code> to analyze the text alongside the metadata.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inaug_words &lt;-<span class="st"> </span>inaug_td %&gt;%
<span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) %&gt;%
<span class="st">  </span><span class="kw">anti_join</span>(stop_words)

inaug_words</code></pre></div>
<pre><code>## # A tibble: 49,621 × 4
##     Year President FirstName         word
##    &lt;int&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;
## 1   2013     Obama    Barack        waves
## 2   2013     Obama    Barack     realizes
## 3   2013     Obama    Barack philadelphia
## 4   2013     Obama    Barack          400
## 5   2013     Obama    Barack           40
## 6   2013     Obama    Barack   absolutism
## 7   2013     Obama    Barack      contour
## 8   2013     Obama    Barack      newtown
## 9   2013     Obama    Barack        lanes
## 10  2013     Obama    Barack   appalachia
## # ... with 49,611 more rows</code></pre>
<p>We could then, for example, see how the appearance of a word changes over time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyr)

inaug_freq &lt;-<span class="st"> </span>inaug_words %&gt;%
<span class="st">  </span><span class="kw">count</span>(Year, word) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>() %&gt;%
<span class="st">  </span><span class="kw">complete</span>(Year, word, <span class="dt">fill =</span> <span class="kw">list</span>(<span class="dt">n =</span> <span class="dv">0</span>)) %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(Year) %&gt;%
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year_total =</span> <span class="kw">sum</span>(n),
         <span class="dt">percent =</span> n /<span class="st"> </span>year_total) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>()

inaug_freq %&gt;%
<span class="st">  </span><span class="kw">filter</span>(word ==<span class="st"> &quot;america&quot;</span>)</code></pre></div>
<pre><code>## # A tibble: 57 × 5
##     Year    word     n year_total     percent
##    &lt;int&gt;   &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1   1789 america     0        529 0.000000000
## 2   1793 america     1         51 0.019607843
## 3   1797 america     5        863 0.005793743
## 4   1801 america     0        634 0.000000000
## 5   1805 america     0        796 0.000000000
## 6   1809 america     0        436 0.000000000
## 7   1813 america     0        456 0.000000000
## 8   1817 america     0       1197 0.000000000
## 9   1821 america     2       1578 0.001267427
## 10  1825 america     0       1153 0.000000000
## # ... with 47 more rows</code></pre>
<p>For instance, we could display the top 6 terms that have changed in frequency over time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(scales)

inaug_freq %&gt;%
<span class="st">  </span><span class="kw">filter</span>(word %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;americans&quot;</span>, <span class="st">&quot;century&quot;</span>, <span class="st">&quot;foreign&quot;</span>, <span class="st">&quot;god&quot;</span>,
                     <span class="st">&quot;union&quot;</span>, <span class="st">&quot;constitution&quot;</span>)) %&gt;%
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Year, percent)) +
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.8</span>) +
<span class="st">  </span><span class="kw">geom_smooth</span>() +
<span class="st">  </span><span class="kw">facet_wrap</span>(~<span class="st"> </span>word, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) +
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels =</span> <span class="kw">percent_format</span>()) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Frequency of word in speech&quot;</span>)</code></pre></div>
<p><img src="06-document-term-matrices_files/figure-html/unnamed-chunk-6-1.png" width="768" /></p>

</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-R-broom">
<p>Robinson, David, Matthieu Gomez, Boris Demeshev, Dieter Menne, Benjamin Nutter, Luke Johnston, Ben Bolker, Francois Briatte, and Hadley Wickham. 2015. <em>Broom: Convert Statistical Analysis Objects into Tidy Data Frames</em>. <a href="https://CRAN.R-project.org/package=broom" class="uri">https://CRAN.R-project.org/package=broom</a>.</p>
</div>
<div id="ref-R-reshape2">
<p>Wickham, Hadley. 2007. “Reshaping Data with the reshape Package.” <em>Journal of Statistical Software</em> 21 (12): 1–20. <a href="http://www.jstatsoft.org/v21/i12/" class="uri">http://www.jstatsoft.org/v21/i12/</a>.</p>
</div>
<div id="ref-R-quanteda">
<p>Benoit, Kenneth, and Paul Nulty. 2016. <em>Quanteda: Quantitative Analysis of Textual Data</em>. <a href="https://CRAN.R-project.org/package=quanteda" class="uri">https://CRAN.R-project.org/package=quanteda</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ngrams.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="topicmodeling.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dgrtwo/tidy-text-mining/edit/master/06-document-term-matrices.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
