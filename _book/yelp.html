<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Tidy Text Mining</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools">
  <meta name="generator" content="bookdown 0.0.74 and GitBook 2.6.7">

  <meta property="og:title" content="Tidy Text Mining" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  <meta name="github-repo" content="dgrtwo/tidy-text-mining" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tidy Text Mining" />
  
  <meta name="twitter:description" content="A guide to text analysis within the tidy data framework, using the tidytext package and other tidy tools" />
  

<meta name="author" content="Julia Silge and David Robinson">

<meta name="date" content="2016-07-07">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="word2vec.html">
<link rel="next" href="placeholder.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Tidy Text Mining</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-tidy-text"><i class="fa fa-check"></i><b>1.1</b> What is tidy text?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#outline"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tidytext.html"><a href="tidytext.html"><i class="fa fa-check"></i><b>2</b> The Tidy Text Format</a><ul>
<li class="chapter" data-level="2.1" data-path="tidytext.html"><a href="tidytext.html#the-unnest_tokens-function"><i class="fa fa-check"></i><b>2.1</b> The <code>unnest_tokens</code> function</a></li>
<li class="chapter" data-level="2.2" data-path="tidytext.html"><a href="tidytext.html#example-the-works-of-jane-austen"><i class="fa fa-check"></i><b>2.2</b> Example: the works of Jane Austen</a><ul>
<li class="chapter" data-level="2.2.1" data-path="tidytext.html"><a href="tidytext.html#the-gutenbergr-package"><i class="fa fa-check"></i><b>2.2.1</b> The gutenbergr package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sentiment.html"><a href="sentiment.html"><i class="fa fa-check"></i><b>3</b> Sentiment Analysis with Tidy Data</a><ul>
<li class="chapter" data-level="3.1" data-path="sentiment.html"><a href="sentiment.html#the-sentiments-dataset"><i class="fa fa-check"></i><b>3.1</b> The sentiments dataset</a></li>
<li class="chapter" data-level="3.2" data-path="sentiment.html"><a href="sentiment.html#sentiment-analysis-with-inner-join"><i class="fa fa-check"></i><b>3.2</b> Sentiment analysis with inner join</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sentiment.html"><a href="sentiment.html#most-common-positive-and-negative-words"><i class="fa fa-check"></i><b>3.2.1</b> Most common positive and negative words</a></li>
<li class="chapter" data-level="3.2.2" data-path="sentiment.html"><a href="sentiment.html#wordclouds"><i class="fa fa-check"></i><b>3.2.2</b> Wordclouds</a></li>
<li class="chapter" data-level="3.2.3" data-path="sentiment.html"><a href="sentiment.html#looking-at-units-beyond-just-words"><i class="fa fa-check"></i><b>3.2.3</b> Looking at units beyond just words</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tfidf.html"><a href="tfidf.html"><i class="fa fa-check"></i><b>4</b> TF-IDF: Analyzing word and document frequency</a><ul>
<li class="chapter" data-level="4.1" data-path="tfidf.html"><a href="tfidf.html#term-frequency-and-inverse-document-frequency"><i class="fa fa-check"></i><b>4.1</b> Term frequency and inverse document frequency</a></li>
<li class="chapter" data-level="4.2" data-path="tfidf.html"><a href="tfidf.html#the-bind_tf_idf-function"><i class="fa fa-check"></i><b>4.2</b> The bind_tf_idf function</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html"><i class="fa fa-check"></i><b>5</b> Tidying and casting document-term matrices</a><ul>
<li class="chapter" data-level="5.1" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#tidying-a-document-term-matrix"><i class="fa fa-check"></i><b>5.1</b> Tidying a document-term matrix</a></li>
<li class="chapter" data-level="5.2" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#casting-tidy-text-data-into-a-documenttermmatrix"><i class="fa fa-check"></i><b>5.2</b> Casting tidy text data into a DocumentTermMatrix</a></li>
<li class="chapter" data-level="5.3" data-path="tidying-and-casting-document-term-matrices.html"><a href="tidying-and-casting-document-term-matrices.html#tidying-corpus-objects-with-metadata"><i class="fa fa-check"></i><b>5.3</b> Tidying corpus objects with metadata</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="topicmodeling.html"><a href="topicmodeling.html"><i class="fa fa-check"></i><b>6</b> Topic Modeling</a><ul>
<li class="chapter" data-level="6.1" data-path="topicmodeling.html"><a href="topicmodeling.html#can-we-tell-the-difference-between-dickens-wells-verne-and-austen"><i class="fa fa-check"></i><b>6.1</b> Can we tell the difference between Dickens, Wells, Verne, and Austen?</a></li>
<li class="chapter" data-level="6.2" data-path="topicmodeling.html"><a href="topicmodeling.html#setup"><i class="fa fa-check"></i><b>6.2</b> Setup</a></li>
<li class="chapter" data-level="6.3" data-path="topicmodeling.html"><a href="topicmodeling.html#latent-dirichlet-allocation-with-the-topicmodels-package"><i class="fa fa-check"></i><b>6.3</b> Latent Dirichlet Allocation with the topicmodels package</a></li>
<li class="chapter" data-level="6.4" data-path="topicmodeling.html"><a href="topicmodeling.html#per-document-classification"><i class="fa fa-check"></i><b>6.4</b> Per-document classification</a><ul>
<li class="chapter" data-level="6.4.1" data-path="topicmodeling.html"><a href="topicmodeling.html#by-word-assignments-augment"><i class="fa fa-check"></i><b>6.4.1</b> By word assignments: <code>augment</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="word2vec.html"><a href="word2vec.html"><i class="fa fa-check"></i><b>7</b> Tidying word2vec Models from the glove Package</a></li>
<li class="chapter" data-level="8" data-path="yelp.html"><a href="yelp.html"><i class="fa fa-check"></i><b>8</b> Predicting ratings from text in the Yelp food reviews dataset</a><ul>
<li class="chapter" data-level="8.1" data-path="yelp.html"><a href="yelp.html#setup-1"><i class="fa fa-check"></i><b>8.1</b> Setup</a></li>
<li class="chapter" data-level="8.2" data-path="yelp.html"><a href="yelp.html#tidy-sentiment-analysis"><i class="fa fa-check"></i><b>8.2</b> Tidy sentiment analysis</a></li>
<li class="chapter" data-level="8.3" data-path="yelp.html"><a href="yelp.html#which-words-are-positive-or-negative"><i class="fa fa-check"></i><b>8.3</b> Which words are positive or negative?</a></li>
<li class="chapter" data-level="8.4" data-path="yelp.html"><a href="yelp.html#comparing-to-sentiment-analysis"><i class="fa fa-check"></i><b>8.4</b> Comparing to sentiment analysis</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="placeholder.html"><a href="placeholder.html"><i class="fa fa-check"></i><b>9</b> Some analysis goes here</a></li>
<li class="chapter" data-level="10" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>10</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Tidy Text Mining</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="yelp" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Predicting ratings from text in the Yelp food reviews dataset</h1>
<p>Intro goes here</p>
<div id="setup-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Setup</h2>
<p>I’ve downloaded the <code>yelp_dataset_challenge_academic_dataset</code> folder from <a href="https://www.yelp.com/dataset_challenge">here</a>.[^termsofuse] First I read and process them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(readr)
<span class="kw">library</span>(dplyr)

<span class="co"># You may have used the built-in readLines before, but read_lines from</span>
<span class="co"># readr is faster for large files</span>

<span class="co"># we&#39;re reading only 100,000 in this example</span>
<span class="co"># you can try it with the full dataset too, it&#39;s just a little slower!</span>
<span class="co"># in the final version of the book we&#39;re probably going to read all, it</span>
<span class="co"># just makes this chapter take a while to compile</span>

infile &lt;-<span class="st"> &quot;~/Downloads/yelp_dataset_challenge_academic_dataset/yelp_academic_dataset_review.json&quot;</span>
review_lines &lt;-<span class="st"> </span><span class="kw">read_lines</span>(infile, <span class="dt">n_max =</span> <span class="dv">100000</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(stringr)

<span class="co"># Each line is a JSON object- the fastest way to process is to combine into a</span>
<span class="co"># single JSON string and use jsonlite::fromJSON</span>
reviews_combined &lt;-<span class="st"> </span><span class="kw">str_c</span>(<span class="st">&quot;[&quot;</span>, <span class="kw">str_c</span>(review_lines, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>), <span class="st">&quot;]&quot;</span>)

reviews &lt;-<span class="st"> </span>jsonlite::<span class="kw">fromJSON</span>(reviews_combined) %&gt;%
<span class="st">  </span>jsonlite::<span class="kw">flatten</span>() %&gt;%
<span class="st">  </span><span class="kw">tbl_df</span>()</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reviews</code></pre></div>
<pre><code>## # A tibble: 100,000 x 10
##                   user_id              review_id stars       date
## *                   &lt;chr&gt;                  &lt;chr&gt; &lt;int&gt;      &lt;chr&gt;
## 1  PUFPaY9KxDAcGqfsorJp3Q Ya85v4eqdd6k9Od8HbQjyA     4 2012-08-01
## 2  Iu6AxdBYGR4A0wspR9BYHA KPvLNJ21_4wbYNctrOwWdQ     5 2014-02-13
## 3  auESFwWvW42h6alXgFxAXQ fFSoGV46Yxuwbr3fHNuZig     5 2015-10-31
## 4  uK8tzraOp4M5u3uYrqIBXg Di3exaUCFNw1V4kSNW5pgA     5 2013-11-08
## 5  I_47G-R2_egp7ME5u_ltew 0Lua2-PbqEQMjD9r89-asw     3 2014-03-29
## 6  PP_xoMSYlGr2pb67BbqBdA 7N9j5YbBHBW6qguE5DAeyA     1 2014-10-29
## 7  JPPhyFE-UE453zA6K0TVgw mjCJR33jvUNt41iJCxDU_g     4 2014-11-28
## 8  2d5HeDvZTDUNVog_WuUpSg Ieh3kfZ-5J9pLju4JiQDvQ     5 2014-02-27
## 9  BShxMIUwaJS378xcrz4Nmg PU28OoBSHpZLkYGCmNxlmg     5 2015-06-16
## 10 fhNxoMwwTipzjO8A9LFe8Q XsA6AojkWjOHA4FmuAb8XQ     3 2012-08-19
## # ... with 99,990 more rows, and 6 more variables: text &lt;chr&gt;, type &lt;chr&gt;, business_id &lt;chr&gt;,
## #   votes.funny &lt;int&gt;, votes.useful &lt;int&gt;, votes.cool &lt;int&gt;</code></pre>
</div>
<div id="tidy-sentiment-analysis" class="section level2">
<h2><span class="header-section-number">8.2</span> Tidy sentiment analysis</h2>
<p>Right now, there is one row for each review. To analyze in the <a href="http://github.com/juliasilge/tidytext">tidy text</a> framework, we need to use the <code>unnest_tokens</code> function and turn this into one-row-per-term-per-document:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidytext)

review_words &lt;-<span class="st"> </span>reviews %&gt;%
<span class="st">  </span><span class="kw">select</span>(review_id, business_id, stars, text) %&gt;%
<span class="st">  </span><span class="kw">unnest_tokens</span>(word, text) %&gt;%
<span class="st">  </span><span class="kw">filter</span>(!word %in%<span class="st"> </span>stop_words$word,
         <span class="kw">str_detect</span>(word, <span class="st">&quot;^[a-z&#39;]+$&quot;</span>))

review_words</code></pre></div>
<pre><code>## # A tibble: 3,971,444 x 4
##                 review_id            business_id stars        word
##                     &lt;chr&gt;                  &lt;chr&gt; &lt;int&gt;       &lt;chr&gt;
## 1  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4      hoagie
## 2  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4 institution
## 3  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4     walking
## 4  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4   throwback
## 5  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4         ago
## 6  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4   fashioned
## 7  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4        menu
## 8  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4       board
## 9  Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4      booths
## 10 Ya85v4eqdd6k9Od8HbQjyA 5UmKMjUEUNdYWqANhGckJw     4   selection
## # ... with 3,971,434 more rows</code></pre>
<p>Notice that there is now one-row-per-term-per-document: the In this cleaning process we’ve also removed “stopwords” (such as “I”, “the”, “and”, etc), and removing things things that are formatting (e.g. “—-”) rather than a word.</p>
<p>Now I’m going to do sentiment analysis on each review. We’ll use the AFINN lexicon, which provides a positivity score for each word, from -5 (most negative) to 5 (most positive).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AFINN &lt;-<span class="st"> </span>sentiments %&gt;%
<span class="st">  </span><span class="kw">filter</span>(lexicon ==<span class="st"> &quot;AFINN&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">select</span>(word, <span class="dt">afinn_score =</span> score)

AFINN</code></pre></div>
<pre><code>## # A tibble: 2,476 x 2
##          word afinn_score
##         &lt;chr&gt;       &lt;int&gt;
## 1     abandon          -2
## 2   abandoned          -2
## 3    abandons          -2
## 4    abducted          -2
## 5   abduction          -2
## 6  abductions          -2
## 7       abhor          -3
## 8    abhorred          -3
## 9   abhorrent          -3
## 10     abhors          -3
## # ... with 2,466 more rows</code></pre>
<p>Now as described <a href="http://juliasilge.com/blog/Life-Changing-Magic/">in this post</a>, our sentiment analysis is just an inner-join operation followed by a summary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reviews_sentiment &lt;-<span class="st"> </span>review_words %&gt;%
<span class="st">  </span><span class="kw">inner_join</span>(AFINN, <span class="dt">by =</span> <span class="st">&quot;word&quot;</span>) %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(review_id, stars) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sentiment =</span> <span class="kw">mean</span>(afinn_score))

reviews_sentiment</code></pre></div>
<pre><code>## Source: local data frame [93,947 x 3]
## Groups: review_id [?]
## 
##                 review_id stars  sentiment
##                     &lt;chr&gt; &lt;int&gt;      &lt;dbl&gt;
## 1  __-r0eC3hZlaejvuliC8zQ     5  4.0000000
## 2  __56FUEaW57kZEm56OZk7w     5  0.8333333
## 3  __6tOxx2VcvGR02d2ILkuw     5  1.7500000
## 4  __77nP3Nf1wsGz5HPs2hdw     5  1.6000000
## 5  __B5KInsYxFKIHKXAS6_rA     1 -2.0000000
## 6  __BIQ3tcFZg6_PpdadEfLQ     4  1.6000000
## 7  __DK9Vsmyoo0zJQhIl5cbg     1 -2.1000000
## 8  __ELCJ0wzDM2QNRfVUq26Q     5  3.5000000
## 9  __esH_kgJZeS8k3i6HaG7Q     5  0.2142857
## 10 __GXnNfKFLqFhMtpCTTT2g     3  0.8750000
## # ... with 93,937 more rows</code></pre>
<p>Now we can see how our estimates did!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(reviews_sentiment, <span class="kw">aes</span>(stars, sentiment, <span class="dt">group =</span> stars)) +
<span class="st">  </span><span class="kw">geom_boxplot</span>() +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Average sentiment score&quot;</span>)</code></pre></div>
<p><img src="tidy-text-mining_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<p>Well, it’s a good start! Our sentiment scores are correlated with positivity ratings. But we do see that there’s a large amount of prediction error- some 5-star reviews have a highly negative sentiment score, and vice versa.</p>
</div>
<div id="which-words-are-positive-or-negative" class="section level2">
<h2><span class="header-section-number">8.3</span> Which words are positive or negative?</h2>
<p>We’re interested in analyzing the properties of words. Which are suggestive of positive reviews, and which are negative? To do this, we’ll create a per-word summary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">review_words_counted &lt;-<span class="st"> </span>review_words %&gt;%
<span class="st">  </span><span class="kw">count</span>(review_id, business_id, stars, word) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>()

review_words_counted</code></pre></div>
<pre><code>## # A tibble: 3,405,173 x 5
##                 review_id            business_id stars      word     n
##                     &lt;chr&gt;                  &lt;chr&gt; &lt;int&gt;     &lt;chr&gt; &lt;int&gt;
## 1  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5    batter     1
## 2  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5     chips     3
## 3  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5  compares     1
## 4  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5 fashioned     1
## 5  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5  filleted     1
## 6  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5      fish     4
## 7  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5     fries     1
## 8  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5    frozen     1
## 9  ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5 greenlake     1
## 10 ___XYEos-RIkPsQwplRYyw YxMnfznT3eYya0YV37tE8w     5      hand     1
## # ... with 3,405,163 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_summaries &lt;-<span class="st"> </span>review_words_counted %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(word) %&gt;%
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">reviews =</span> <span class="kw">n</span>(),
            <span class="dt">uses =</span> <span class="kw">sum</span>(n),
            <span class="dt">average_stars =</span> <span class="kw">mean</span>(stars)) %&gt;%
<span class="st">  </span><span class="kw">ungroup</span>()

word_summaries</code></pre></div>
<pre><code>## # A tibble: 73,816 x 4
##          word reviews  uses average_stars
##         &lt;chr&gt;   &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;
## 1   a&#39;boiling       1     1          4.00
## 2      a&#39;fare       1     1          4.00
## 3      a&#39;ight       2     2          1.50
## 4        a&#39;la       2     2          4.50
## 5        a&#39;ll       1     1          1.00
## 6      a&#39;lyce       1     2          5.00
## 7      a&#39;more       2     2          5.00
## 8    a&#39;orange       1     1          5.00
## 9  a&#39;prowling       1     1          3.00
## 10         aa      20    23          3.25
## # ... with 73,806 more rows</code></pre>
<p>We can start by looking only at words that appear in at least 100 (out of 100000) reviews. This makes sense both because words that appear more rarely will have a noisier measurement (a few good or bad reviews could shift the balance), and because they’re less likely to be useful in classifying future reviews or text.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_summaries_filtered &lt;-<span class="st"> </span>word_summaries %&gt;%
<span class="st">  </span><span class="kw">filter</span>(reviews &gt;=<span class="st"> </span><span class="dv">100</span>)

word_summaries_filtered</code></pre></div>
<pre><code>## # A tibble: 4,465 x 4
##          word reviews  uses average_stars
##         &lt;chr&gt;   &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;
## 1         aaa     100   145      3.780000
## 2     ability     210   215      3.580952
## 3    absolute     589   600      3.755518
## 4  absolutely    3195  3401      3.812520
## 5          ac     306   420      3.058824
## 6      accent     112   115      3.446429
## 7      accept     350   370      3.060000
## 8  acceptable     313   319      2.645367
## 9    accepted     162   167      3.030864
## 10     access     530   588      3.541509
## # ... with 4,455 more rows</code></pre>
<p>What were the most positive and negative words?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_summaries_filtered %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(average_stars))</code></pre></div>
<pre><code>## # A tibble: 4,465 x 4
##             word reviews  uses average_stars
##            &lt;chr&gt;   &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;
## 1       exceeded     160   161      4.675000
## 2   knowledgable     371   374      4.630728
## 3  compassionate     112   115      4.625000
## 4      exquisite     108   112      4.601852
## 5        chihuly     117   151      4.547009
## 6       treasure     152   159      4.546053
## 7    compliments     212   215      4.542453
## 8            gem     982   997      4.518330
## 9      botanical     184   241      4.510870
## 10   trustworthy     105   105      4.495238
## # ... with 4,455 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">word_summaries_filtered %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(average_stars)</code></pre></div>
<pre><code>## # A tibble: 4,465 x 4
##              word reviews  uses average_stars
##             &lt;chr&gt;   &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;
## 1     incompetent     156   167      1.423077
## 2  unprofessional     362   383      1.447514
## 3       disgusted     124   126      1.475806
## 4          rudely     167   179      1.520958
## 5            lied     154   177      1.532468
## 6          refund     390   497      1.558974
## 7         refused     455   507      1.610989
## 8    unacceptable     201   203      1.616915
## 9           worst    2433  2653      1.619400
## 10         denied     100   111      1.650000
## # ... with 4,455 more rows</code></pre>
<p>Makes a lot of sense! We can also plot positivity by frequency:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(word_summaries_filtered, <span class="kw">aes</span>(reviews, average_stars)) +
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> word), <span class="dt">check_overlap =</span> <span class="ot">TRUE</span>, <span class="dt">vjust =</span> <span class="dv">1</span>, <span class="dt">hjust =</span> <span class="dv">1</span>) +
<span class="st">  </span><span class="kw">scale_x_log10</span>() +
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">mean</span>(reviews$stars), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>) +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;# of reviews&quot;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Average Stars&quot;</span>)</code></pre></div>
<p><img src="tidy-text-mining_files/figure-html/word_summaries_filtered_plot-1.png" width="672" /></p>
<p>Note that some of the most common words (e.g. “food”) are pretty neutral. There are some common words that are pretty positive (e.g. “amazing”, “awesome”) and others that are pretty negative (“bad”, “told”).</p>
</div>
<div id="comparing-to-sentiment-analysis" class="section level2">
<h2><span class="header-section-number">8.4</span> Comparing to sentiment analysis</h2>
<p>When we perform sentiment analysis, we’re often comparing to a pre-existing lexicon, one that was developed.</p>
<p>The tidytext package also comes with several tidy sentiment analysis lexicons:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sentiments</code></pre></div>
<pre><code>## # A tibble: 23,165 x 4
##           word sentiment lexicon score
##          &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
## 1       abacus     trust     nrc    NA
## 2      abandon      fear     nrc    NA
## 3      abandon  negative     nrc    NA
## 4      abandon   sadness     nrc    NA
## 5    abandoned     anger     nrc    NA
## 6    abandoned      fear     nrc    NA
## 7    abandoned  negative     nrc    NA
## 8    abandoned   sadness     nrc    NA
## 9  abandonment     anger     nrc    NA
## 10 abandonment      fear     nrc    NA
## # ... with 23,155 more rows</code></pre>
<p>We might expect that more positive words are associated with higher star reviews. Does this hold? We can combine and compare the two datasets with <code>inner_join</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">words_afinn &lt;-<span class="st"> </span>word_summaries_filtered %&gt;%
<span class="st">  </span><span class="kw">inner_join</span>(AFINN)

words_afinn</code></pre></div>
<pre><code>## # A tibble: 520 x 5
##            word reviews  uses average_stars afinn_score
##           &lt;chr&gt;   &lt;int&gt; &lt;int&gt;         &lt;dbl&gt;       &lt;int&gt;
## 1       ability     210   215      3.580952           2
## 2        accept     350   370      3.060000           1
## 3      accepted     162   167      3.030864           1
## 4      accident     213   239      3.629108          -2
## 5  accidentally     152   152      3.348684          -2
## 6        active     109   115      3.981651           1
## 7      adequate     290   304      3.262069           1
## 8         admit     740   754      3.666216          -1
## 9      admitted     111   118      2.225225          -1
## 10     adorable     255   266      4.250980           3
## # ... with 510 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(words_afinn, <span class="kw">aes</span>(afinn_score, average_stars, <span class="dt">group =</span> afinn_score)) +
<span class="st">  </span><span class="kw">geom_boxplot</span>() +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;AFINN score of word&quot;</span>) +
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Average stars of reviews with this word&quot;</span>)</code></pre></div>
<p><img src="tidy-text-mining_files/figure-html/words_afinn-1.png" width="672" /></p>
<p>Just like in our per-review predictions, there’s a very clear trend. AFINN sentiment analysis works, at least a little bit!</p>
<p>But we may want to see some of those details. Which positive/negative words were most successful in predicting a positive/negative review, and which broke the trend?</p>
<p><img src="tidy-text-mining_files/figure-html/words_afinn_plot-1.png" width="960" /></p>
<pre><code>## mapping: x = x 
## geom_blank: na.rm = FALSE
## stat_identity: na.rm = FALSE
## position_identity</code></pre>
<p>For example, we can see that most curse words have an AFINN score of -4, and that while some words, like “wtf”, successfully predict a negative review, others, like “damn”, are often positive. (They’re likely part of “damn good”, or something similar). Some of the words that AFINN most underestimated included “die” (“the pork chops are to <strong>die</strong> for!”), and one of the words it most overestimated was “joke” (“the service is a complete <strong>joke</strong>!”).</p>
<p>One other way we could look at mis</p>
<p><img src="tidy-text-mining_files/figure-html/word_summaries_filtered_plot_AFINN-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="word2vec.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="placeholder.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dgrtwo/tidy-text-mining/edit/master/08-yelp-reviews.Rmd",
"text": null
},
"download": ["tidy-text-mining.pdf", "tidy-text-mining.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
