# Case study: comparing Twitter archives {#twitter}

One type of text that has gotten a good deal of attention in recent years is text shared online via Twitter. In fact, several of the sentiment lexicons used in this book (and commonly used in general) were designed for use with and validated on tweets. Both of the authors of this book are on Twitter and are fairly regular users of it so in this case study, let's compare the entire Twitter archives of Julia and David.

## Getting the data and distribution of tweets

An individual can download their own Twitter archive by following [directions available here](https://support.twitter.com/articles/20170160). We each downloaded ours and will now open them up. Let's use lubridate to convert the string timestamps to date-time objects and just take a look at our tweeting patterns overall.

```{r setup, fig.width=8, fig.height=5}
library(lubridate)
library(ggplot2)
library(dplyr)
tweets_julia <- read.csv("data/tweets_julia.csv", stringsAsFactors = FALSE)
tweets_dave <- read.csv("data/tweets_dave.csv", stringsAsFactors = FALSE)
tweets_julia$timestamp <- with_tz(ymd_hms(tweets_julia$timestamp), 
                                  "America/Denver")
tweets_dave$timestamp <- with_tz(ymd_hms(tweets_dave$timestamp), 
                                 "America/New_York")
tweets <- bind_rows(tweets_julia %>% mutate(person = "Julia"),
                    tweets_dave %>% mutate(person = "David"))
ggplot(tweets, aes(x = timestamp, fill = person)) +
  geom_histogram(alpha = 0.5, position = "identity")
```
David and Julia tweet at about the same rate currently and joined Twitter about a year apart from each other, but there good 5 or so years where David was not active on Twitter and Julia was. In total, Julia has about 4 times as many tweets as David.

## Word frequencies

Let's use `unnest_tokens` to make a tidy dataframe of all the words in our tweets, and remove the common English stop words.

```{r tidytweets, dependson = "setup"}
library(tidytext)
tidy_tweets <- tweets %>% unnest_tokens(word, text) %>% anti_join(stop_words)
```

Now we can calculate word frequencies for each person

```{r frequency, dependson = "tidytweets"}
frequency <- tidy_tweets %>% group_by(person) %>% 
  count(word, sort = TRUE) %>% 
  left_join(tidy_tweets %>% group_by(person) %>% summarise(total = n())) %>%
  mutate(freq = n/total)
frequency
```

This is a lovely, tidy data frame but we would actually like to plot those frequencies on the x- and y-axes of a plot, so we will need to use an `inner_join` and make a different dataframe.

```{r spread, dependson = "frequency", fig.height=7, fig.width=7}
frequency <- inner_join(frequency %>% filter(person == "Julia") %>% rename(Julia = freq),
                        frequency %>% filter(person == "David") %>% rename(David = freq),
                        by = "word") %>% 
  ungroup() %>% select(word, Julia, David)
frequency

library(scales)
ggplot(frequency, aes(Julia, David)) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.4, height = 0.4) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = "red")
```


It is at this point that we should perhaps share some personal details. Although the authors of this book enjoy working together very much, it could be argued that their lives are quite different. To start with, David is about 10 years younger than Julia. Also, Julia has three children, two of who were born during the years she has been active on Twitter; we could find the tweets where she complained about being very pregnant or announced their births if we wanted to. David has used his Twitter account almost exclusively for professional purposes since he became more active, while Julia used it for entirely personal purposes until late 2015. We see these differences immediately in this plot exploring word frequencies, and they will continue to be obvious.

TODO: lots
